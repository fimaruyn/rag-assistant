# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: (25000, 62)
- Целевая переменная: `target` (Class 0: 95.08%, Class 1: 4.92%)
- Признаки: Все числовые признаки, синтетические данные с сильным дисбалансом классов.

## 2. Protocol

- Разбиение: 80% train / 20% test, `random_state=42`, `stratify=y`
- Подбор: 5-fold StratifiedKFold на train, оптимизация по F1-score (критично для дисбаланса)
- Метрики: accuracy (базовая метрика), F1 (учитывает дисбаланс классов), ROC-AUC (показывает качество ранжирования вероятностей). Выбор обусловлен необходимостью оценки качества при сильном дисбалансе классов.

## 3. Models

Сравнивались следующие модели:

1. DummyClassifier (baseline, strategy='stratified')
2. LogisticRegression (через pipeline со StandardScaler, class_weight='balanced')
3. DecisionTreeClassifier (подбор max_depth [3,5,7,10] и min_samples_leaf [5,10,20])
4. RandomForestClassifier (подбор max_depth [10,15,None], min_samples_leaf [2,5], max_features ['sqrt','log2'])
5. HistGradientBoostingClassifier (современная реализация градиентного бустинга)
6. StackingClassifier (DecisionTree + RandomForest + HistGradientBoosting в качестве базовых моделей, LogisticRegression с class_weight='balanced' как метамодель)

Все модели обучались с параметром class_weight='balanced' для компенсации дисбаланса классов. Наилучшие гиперпараметры:

- DecisionTree: max_depth=10, min_samples_leaf=5
- RandomForest: max_depth=10, max_features='sqrt', min_samples_leaf=5

## 4. Results

**Финальные метрики на тестовой выборке:**
| Модель | Accuracy | F1 | ROC-AUC |
|--------|----------|-----|---------|
| DummyClassifier | 0.9050 | 0.0365 | 0.4933 |
| LogisticRegression | 0.7756 | 0.2540 | 0.8355 |
| DecisionTree | 0.8948 | 0.3826 | 0.7860 |
| RandomForest | 0.9746 | **0.7171** | 0.9014 |
| HistGradientBoosting | 0.9560 | 0.6370 | 0.8994 |
| StackingClassifier | 0.9174 | 0.4920 | **0.9023** |

Победитель: **StackingClassifier** по метрике ROC-AUC (0.9023), при этом RandomForest показал наилучший результат по F1 (0.7171). Выбор StackingClassifier в качестве финальной модели обусловлен оптимальным балансом между способностью к ранжированию (ROC-AUC) и обобщающей способностью, а также стабильностью работы с дисбалансированными данными.

## 5. Analysis

**Устойчивость:** Анализ с различными random_state (10, 42, 100, 200, 300) показал, что разброс ROC-AUC для StackingClassifier составил ±0.015, что говорит о стабильности решения. RandomForest демонстрировал больший разброс по F1 (±0.05).

**Ошибки:** Confusion matrix для StackingClassifier:
```
[[4387  367]
 [  46  200]]
```
Матрица показывает: 4387 True Negative, 367 False Positive, 46 False Negative, 200 True Positive. Высокая точность (TP+TN)/(общее количество) в 91.74%, но модель склонна к ложным срабатываниям (367 FP) при относительно небольшом количестве ложноотрицательных результатов (46 FN). Это типично для задач с дисбалансом классов и объясняет разрыв между высокой accuracy (0.9174) и умеренной F1 (0.4920).

**Интерпретация:** Permutation importance выявил следующие top-10 признаков:
1. f58
2. f25
3. f54
4. f38
5. f53
6. f33
7. f41
8. f04
9. f47
10. f08

Признаки f58, f25 и f54 имеют наибольшее влияние на предсказания модели. Это согласуется с синтетической природой данных и подтверждает, что модель фокусируется на аномальных паттернах для выявления редкого класса.

## 6. Conclusion

1. При сильном дисбалансе классов accuracy является вводящей в заблуждение метрикой: RandomForest показывает 97.46% accuracy, но это в основном за счет правильного предсказания majority-класса.
   
2. Компромиссы между метриками критичны для выбора модели: StackingClassifier выигрывает по ROC-AUC (качество ранжирования), а RandomForest - по F1 (баланс precision и recall для minority-класса).

3. Ансамбли (RandomForest, HistGradientBoosting, Stacking) существенно превосходят одиночные модели (DecisionTree, LogisticRegression), что демонстрирует их эффективность при работе с зашумленными и несбалансированными данными.

4. Честный ML-протокол с фиксированным разделением данных, кросс-валидацией на тренировочной выборке и однократной оценкой на тестовой выборке необходим для получения объективных результатов.

5. Использование class_weight='balanced' во всех моделях критически важно для дисбалансированных данных, без этого большинство моделей игнорировали бы minority-класс.

6. Stacking показал наилучшую способность к ранжированию (ROC-AUC), но требует больше вычислительных ресурсов и сложнее в интерпретации по сравнению с отдельными деревьями или лесом.