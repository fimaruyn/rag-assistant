# HW07 – Report

> Файл: `homeworks/HW07/report.md`  

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):
- S07-hw-dataset-01.csv
- S07-hw-dataset-02.csv 
- S07-hw-dataset-04.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 8)
- Признаки: 8 числовых признаков
- Пропуски: нет
- "Подлости" датасета: признаки в сильно разных шкалах + шумовые признаки, что делает критически важным этап масштабирования

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 3)
- Признаки: 3 числовых признака
- Пропуски: нет
- "Подлости" датасета: нелинейная структура кластеров + выбросы + шумовой признак, что делает KMeans неэффективным

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000, 32)
- Признаки: 30 числовых + 2 категориальных признака
- Пропуски: 5915 пропусков в числовых признаках
- "Подлости" датасета: высокая размерность + категориальные признаки + значительное количество пропусков, требующие комплексного препроцессинга

## 2. Protocol

**Препроцессинг:**
- Для ds1: масштабирование всех признаков с помощью StandardScaler
- Для ds2: масштабирование всех признаков с помощью StandardScaler
- Для ds4: комплексный препроцессинг с использованием ColumnTransformer:
  * Числовые признаки: SimpleImputer(strategy='mean') → StandardScaler
  * Категориальные признаки: SimpleImputer(strategy='most_frequent') → OneHotEncoder(handle_unknown='ignore')

**Поиск гиперпараметров:**
- Для KMeans проверяли диапазон k от 2 до 10 для всех датасетов
- Для DBSCAN (ds2) проверяли комбинации: eps ∈ {0.3, 0.5, 0.7, 1.0, 1.5}, min_samples ∈ {5, 10, 15}
- Для AgglomerativeClustering проверяли все варианты linkage ('ward', 'complete', 'average', 'single')
- При выборе "лучшего" решения руководствовались не только максимумом silhouette_score, но и визуальной интерпретацией, долей шума (для DBSCAN) и устойчивостью результатов

**Метрики:**
- silhouette_score (выше — лучше)
- davies_bouldin_score (ниже — лучше) 
- calinski_harabasz_score (выше — лучше)
- Для DBSCAN метрики рассчитывались только на non-noise точках (исключая label=-1)

**Визуализация:**
- PCA(2D) для всех датасетов с раскраской по кластерам
- t-SNE для ds2 с параметрами: perplexity=30, random_state=42
- Графики silhouette_score vs k для KMeans
- Сравнительные графики разных методов кластеризации

## 3. Models

**Dataset A (ds1):**
- KMeans: подбор k от 2 до 10, random_state=42, n_init=10
- AgglomerativeClustering: подбор linkage ('ward', 'complete', 'average', 'single'), k=2 (оптимальное)

**Dataset B (ds2):**
- KMeans: подбор k от 2 до 10, random_state=42, n_init=10
- DBSCAN: подбор eps и min_samples (сетка параметров как указано в протоколе)

**Dataset C (ds4):**
- KMeans: подбор k от 2 до 10, random_state=42, n_init=10
- AgglomerativeClustering: подбор linkage ('ward', 'complete', 'average', 'single'), k=5 (оптимальное)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

### 4.1 Dataset A
- Лучший метод и параметры: AgglomerativeClustering с linkage="ward", k=2
- Метрики (silhouette / DB / CH): 0.5216 / 0.6853 / 11786.95
- Коротко: решение разумно, так как AgglomerativeClustering с linkage="ward" продемонстрировал идеальную устойчивость (ARI=1.0) при работе с признаками в разных шкалах, где геометрия кластеров хорошо соответствует "шарам". Визуализация PCA подтверждает четкое разделение на два кластера.

### 4.2 Dataset B
- Лучший метод и параметры: DBSCAN с eps=0.7, min_samples=15
- Метрики (silhouette / DB / CH): 0.3488 / 0.8200 / 133.20
- Доля шума: 5.05%
- Коротко: DBSCAN выбран как метод, способный работать с нелинейными формами кластеров и выбросами. KMeans показал худшие результаты (макс. silhouette=0.31) из-за геометрических ограничений. Небольшая доля шума (5.05%) адекватна для данного датасета, что подтверждается визуальной интерпретацией PCA.

### 4.3 Dataset C
- Лучший метод и параметры: AgglomerativeClustering с linkage="ward", k=5
- Метрики (silhouette / DB / CH): 0.4480 / 0.9757 / 5103.10
- Коротко: для сложного высокоразмерного датасета с пропусками и категориальными признаками AgglomerativeClustering показал лучшую способность выделять содержательные кластеры. Выбор оптимален по всем трем метрикам качества одновременно (максимальный silhouette, минимальный Davies-Bouldin, максимальный Calinski-Harabasz), что подтверждает надежность решения.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на Dataset B из-за нелинейной структуры кластеров, которую он принципиально не может воспроизвести из-за своей геометрической природы (разделение гиперплоскостями).
- DBSCAN выигрывает на Dataset B благодаря способности обнаруживать кластеры произвольной формы и устойчивости к выбросам. AgglomerativeClustering выигрывает на Dataset A и C из-за лучшей устойчивости к шумовым признакам и способности работать с данными разных масштабов.
- Наибольшее влияние на результат оказал препроцессинг: для Dataset A масштабирование было критически важно, для Dataset C комплексная обработка пропусков и кодирование категориальных признаков определили возможность вообще применить кластеризацию.


### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости проводилась для Dataset A через 5 запусков KMeans с разными random_state.
- Все запуски показали абсолютно идентичные результаты (ARI=1.0), что демонстрирует идеальную воспроизводимость кластеризации.
- Вывод: решение устойчиво, что связано с четкой структурой данных и правильным выбором количества кластеров. Это подтверждает корректность подхода к данному датасету.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через анализ профилей кластеров по основным признакам (средние значения числовых признаков, распределение категориальных).
- Для Dataset A кластеры четко разделяются по главной компоненте, соответствующей наиболее информативному признаку.
- Для Dataset B кластеры соответствуют нелинейно разделенным областям пространства признаков.
- Для Dataset C кластеры показывают содержательные различия по профилям признаков, что делает их интерпретируемыми в предметной области.

## 6. Conclusion

1. Кластеризация требует тщательного препроцессинга: масштабирование критически важно для distance-based методов.
2. Нет универсального алгоритма: выбор метода должен основываться на структуре данных (линейность, плотность, выбросы).
3. Внутренние метрики качества иногда противоречат друг другу, необходима визуальная интерпретация результатов.
4. Устойчивость результатов (воспроизводимость) так же важна, как и значения метрик при выборе лучшего решения.
5. DBSCAN эффективен для нелинейных структур, но требует аккуратного подбора параметров и работы с шумом.
6. AgglomerativeClustering демонстрирует высокую устойчивость для данных с признаками в разных шкалах и сложной структурой.
7. PCA-визуализация незаменима для интерпретации результатов кластеризации в многомерных данных.
8. Честный unsupervised-протокол требует строгой фиксации всех этапов препроцессинга и параметров алгоритмов.