# S03 – eda_cli: мини-EDA для CSV

Небольшое CLI-приложение для базового анализа CSV-файлов.
Используется в рамках Семинара 03 курса «Инженерия ИИ».

## Требования

- Python 3.11+
- [uv](https://docs.astral.sh/uv/) установлен в систему

## Инициализация проекта

В корне проекта (S03):

```bash
uv sync
```

Эта команда:

- создаст виртуальное окружение `.venv`;
- установит зависимости из `pyproject.toml`;
- установит сам проект `eda-cli` в окружение.

## Доступные команды CLI

### 1. Краткий обзор (`overview`)

```bash
uv run eda-cli overview data/example.csv
```

Параметры:

- `--sep` – разделитель (по умолчанию `,`);
- `--encoding` – кодировка (по умолчанию `utf-8`).

### 2. Полный EDA-отчёт (`report`)

```bash
uv run eda-cli report data/example.csv --out-dir reports
```

Дополнительные параметры:

- `--max-hist-columns` – сколько числовых колонок включать в набор гистограмм (по умолчанию 6)
- `--top-k-categories` – сколько top-значений выводить для категориальных признаков (по умолчанию 5)
- `--title` – заголовок отчёта (по умолчанию "EDA-отчёт")
- `--min-missing-share` – порог доли пропусков для выделения проблемных колонок (по умолчанию 0.1 = 10%)

Пример вызова с расширенными параметрами:

```bash
uv run eda-cli report data/example.csv \
  --out-dir enhanced_reports \
  --max-hist-columns 8 \
  --top-k-categories 10 \
  --title "Подробный анализ данных клиента" \
  --min-missing-share 0.15
```

## Что включает отчёт

В результате в указанном каталоге будут созданы следующие файлы:

- `report.md` – основной отчёт в Markdown с указанным заголовком;
- `summary.csv` – таблица по колонкам;
- `missing.csv` – пропуски по колонкам;
- `correlation.csv` – корреляционная матрица (если есть числовые признаки);
- `top_categories/*.csv` – top-k категорий по строковым признакам (с указанным количеством значений);
- `hist_*.png` – гистограммы для указанного количества числовых колонок;
- `missing_matrix.png` – визуализация пропусков с выделением проблемных колонок;
- `correlation_heatmap.png` – тепловая карта корреляций.

## Особенности анализа качества данных

Отчёт теперь включает расширенные эвристики качества данных:

- **Проверка на константные колонки** (`has_constant_columns`) – выявляет колонки, где все непустые значения одинаковые
- **Проверка на высокую кардинальность** (`has_high_cardinality_categoricals`) – определяет категориальные признаки с большим числом уникальных значений
- **Порог пропусков** – колонки с долей пропусков выше указанного порога выделяются как проблемные

Интегральный показатель качества данных (`quality_score`) учитывает все эти факторы, позволяя быстро оценить пригодность данных для анализа.

## Тесты

```bash
uv run pytest -q
```